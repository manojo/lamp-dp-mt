\documentclass[11pt]{article}
\input{inc/style.sty}

\title{DynaProg for Scala}
\subtitle{A Scala DSL for Dynamic Programming on CPU and GPU}
\begin{document}
\maketitle
%\shorttitle

% Paper introduction:
% Problem to solve, what exists (related work) and how do we compare to other
% Contributions (3): 3 tensed sentences
% Benchmarks => evaluation metrics, prove introduction statements by evaluation
\subsection*{Abstract}
Dynamic programming is a common pattern of Computer Science used in various domains. Yet underlying matrix recurrences might be difficult to express and error prone. Additionally, domain experts might not have the skills to make an efficient parallel implementation. In this project, we present \textit{DynaProg}, a Scala DSL for dynamic programming on heterogeneous platforms which allow to write concise programs and execute them efficiently on GPUs.

Existing work is a DSL embedded in Haskell \cite{adp} with possible conversion to CUDA code \cite{adp_gpu}, a compiler for a dynamic programming external DSL into C code \cite{gapc} or ad-hoc CUDA implementations for specific problem classes \cite{swat_mega}, \cite{gpu_atlp}.
% XXX: How we compare to other, how to evaluate
% Benchmark => prove by evaluation intro statements

Our contributions are: \ul
%\item A classification of DP problems characteristics (matrix shape, dependency graph, ...)
\item A systematic approach to process data (top-down/bottom-up) and backtracking information (focus on running time and memory efficiency)
\item A language embedded in Scala (DSL) to express DP problems concisely (based on ADP)
\item Two implementations: Scala for CPU (features) and an CUDA for GPU (efficiency)
%\item Reuse of existing compiler technology (fusion) for a specific purpose
%\item State of the art parallel implementation of these classes on GPUs
%\item Normalization of the grammar into efficient productions
%\item Code generator to transform a grammar into efficient code for CPU, GPU (and FPGA)
\ule

\vfill
This project has been achieved in collaboration with Manohar Jonnalagedda. I also would like to thank the LAMP team, including Eugene Burmako, Andro Stucki, Vojin Jovanovic and Tiark Rompf who provided insightful advices and suggestions. I hope you will enjoy your reading. \vspace{.3cm}\\
\textit{Thierry Coppey}

\newpage
\setcounter{tocdepth}{2} \tableofcontents

\input{introduction}
\input{problems}
\input{design}
\input{implementation}
\section{Benchmarks}
{\color{red} XXX}

Compare current implementation versus ad-hoc implementation. Compare CUDA vs Scala (we might need to ad-hoc fix stack overflows in Scala).
If Zuker coefficients can be fixed, compare performance with \cite{adp_gpu} by rescaling numbers wrt to bandwidth and computation performance.

\section{Future work}
We consider several directions and possible extensions for our work. We briefly describe each of them and give an idea of how they could be implemented:\ol
\item \textbf{Non-serial scheduling for problems larger than the device memory:} as described in \ref{ns_mem_transfer}, it could be possible to handle problems that are larger than the device memory in a general context, with the extra penalties of memory transfers between main and device memory and a more complex indexing strategy (since we need to find the matrix block in which lies the data, then address the element within the block.

Since recent CUDA devices implement the possibility to address host memory directly from the device, a simple change in the memory allocation strategy could allow larger problems to be solved within the main memory instead of the GPU memory. However, a more thorough analysis on the addressing cost and load penalties should be done to decide which of the strategy is the best.

{\color{red} XXX: need to force 64 bits mode -m64}

% http://www.opensource.apple.com/source/xnu/xnu-2050.18.24/osfmk/vm/vm_map.c : add_wire_counts


 large problems (with memory loads for non-serializable)
\ole

 \ul
\item Implementation for serial problems larger than memory, using hybrid (Myers and Miller's algorithm with $\log_k$ with $k$ depending on available memory)
\item Transforming non-serial into serial using aggregation functions/transformations
\item Avoid to maintain the cost matrix in memory by moving data in the wavefront
\item 
\item Add FPGA target platform (George Nithin)
\item Pack the data => less memory transfer (i.e. GATC=>4 letters in 1 char)
\item Operate on larger words (ex 64 bits) to increase thread locality and reduce memory accesses
\ule

\begin{verbatim}
How to Encode multi-dimensional matrices efficiently
1. assume they have the same type put one after another => different dimensions ok
2. assume of same size => put into a struct
=> but using different pointers seems more reliable => completely different matrices => fixed list of matrices by dimensionality (O(1), O(n), O(n^2), ...) of structs (determined by number of indices to access object)

Core function F:
- in: s,t strings, neighbor costs: top, left, top+left, neighbor stats: top, left, top+left
- out: backtrack information, cost(i,j), stats
         stats (x)
          ||
          vv
stats -> [  ] -> new_stats (y')
(y)       || \
          vv  --+ backtrack info (Bxy)
      new_stats (x')

For stats, we need to maintain an horizontal and vertical front
For backtracking we need to maintain the whole table
... | . |
..A | B | min/max: Min(D)=Min(Min(C),Min(B))
----+---+ sum    : Sum(D)=Sum(C)+Sum(B)-Sum(A)
..C | D | avg    : sum both #cells and values then divide at appropriate cell
----+---+
we may not need to store what's the previous cell, however, the previous
cell information (usually limited range) is much more compact than the score(32-64 bits)
\end{verbatim}

\section{Conclusion}
{\color{red} XXX}

% ------------------------------------------------------------------------------------------------
\section*{Planning}
\subsubsection*{Todo @TCK}\ul
\item Test/proof parsers are correct -- make sure implementation is correct
\item Automate test to compare against implementation
\item Benchmarks -- use CUDA profiler(?)
\item Write report
\item Port LibRNA for CUDA?
\ule

\subsubsection*{Todo @Manohar}\ul
\item Integrate LMS code generation into v4.
\item Fix Zuker coefficients
\ule

Legacy roadmap deadlines: \\
\begin{tabular}{ll}
Nov 16 & Rules normalization and automatic backtracking \\
	& GenScala on LMS + GenCuda + LMS CudaCompiler \\
Nov 23 & Problem generalization: "cyclic keyword", Zucker problem / CudaLoop optimization \\
Nov 30 &--- gap due to LMS missing knowledge --- \\
Dec 7 & Benchmarking, grammar analysis \\
Dec 14 & First thoughts for larger than device memory \\
Dec 21 & Writing report \\
Jan 4 & --- holiday --- \\
Jan 18 & Writing report: implementation description and plan for future work
\end{tabular}

\subsubsection*{Journal}
\begin{tabular}{ll}
Sep. 17	& Getting started with the project, reading related work on hash maps. \\
Sep. 24	& Parallel hashing paper solve the problem for 32bit key/value pair. Stripped CudPP. \\
		& Devised (but not implemented) extension beyond 64bit using memory areas locks. \\
---		& Change of project suggested by Vojin (supervisor): joint work with Manohar on DP \\
Oct. 01	& Problems specifications: serial/non-serial, started CUDA implementation with blocks. \\
Oct. 08	& CudAlign solves serial monadic, might adapt it (but complicated / ad-hoc / in progress). \\
		& Focus on non-serial problems that fit in GPU memory. \\
Oct. 15	& First working implementation for non-serial problems (rectangle, triangle, parallelogram) \\
Oct. 22	& No workaround for timeout, fixed by multiple kernels. Implemented backtrack on GPU. \\
Oct. 29	& Scala/C compiler engine, to use Scala/CUDA, C code must be provided. \\
Nov. 05	& Multiple fixes and rework of ADP parsers to aim at generating C-like code. \\
Nov. 12	& Rework ADP parsers: cyclic, two-track grammars and automatic backtracking discussion. \\
Nov. 19	& Explorations LMS and Macros for C code, implementation is quite different, hence ad-hoc. \\
Nov. 26	& Full backtracking stack: apply / unapply / reapply, refactoring of the classes. \\
Dec. 03	& JNI for LibRNA to get coefficients for Zuker, errors in algebra (quite hairy code). \\
Dec. 10	& Rework concatenation operators, yield analysis, code generation. \\
Dec. 17	& Detupling, generic backtrack (vs. ad-hoc), nested aggregates, empty results support. \\
Dec. 24	& (sick 4 days), code generation: full JNI conversion support, rework CodeCompiler. \\
Dec. 31	& Writing report (design, implementation), fixing various issues, complexity analysis. \\
Jan. 7	& {\color{red} XXX} \\
Jan. 14	& {\color{red} XXX} \\
\end{tabular}

%Some GPU algorithms: http://hgpu.org/?cat=11
%Translation into C++: http://bibiserv.cebitec.uni-bielefeld.de/macports/resources/download/
%CUDPP libraries (but awfully big resulting binary): http://code.google.com/p/cudpp/
%13 dwarfs: http://developer.amd.com/afds/assets/presentations/2155_final.pdf
%http://tutorials.jenkov.com/java-reflection/fields.html
%http://lampwww.epfl.ch/~michelou/scala/scala-reflection.html
%
%Hint: use TypeClass to put a predicate on types
%  def fun[T: CanTranslateToC](...)
%  def fun[T](implicit ev:CanTranslateToC[T])
%  class CanTranslateToC[T] { def translate:String }
%  implicit def canTranslateInt = new CanTranslateToC[Int] = { def translate = "Int" }

% ------------------------------------------------------------------------------------------------
\newpage
%\usepackage{multicol}
%\usepackage{etoolbox}
%\patchcmd{\thebibliography}{\section*{\refname}}{\begin{multicols}{2}[\section*{\refname}]}{}{}
%\patchcmd{\endthebibliography}{\endlist}{\endlist\end{multicols}}{}{}
%\bibliographystyle{acm}
\bibliographystyle{plain}
\bibliography{bibliography.bib}
\end{document}
