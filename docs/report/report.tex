\documentclass[11pt]{article}
\input{inc/style.sty}

\title{DynaProg for Scala}
\subtitle{A Scala DSL for Dynamic Programming on CPU and GPU}
\begin{document}
\maketitle
%\shorttitle

\subsection*{Abstract}
Dynamic programming is a common pattern of Computer Science used in various domains. Yet underlying matrix recurrences might be difficult to express and error prone. Additionally, domain experts might not have the skills to make an efficient parallel implementation. In this project, we present \textit{DynaProg}, a Scala DSL for dynamic programming on heterogeneous platforms which allow to write concise programs and execute them efficiently on GPUs.

Existing work is a DSL embedded in Haskell \cite{adp} with possible conversion to CUDA code \cite{adp_gpu}, a compiler for a dynamic programming external DSL into C code \cite{gapc} or ad-hoc CUDA implementations for specific problem classes \cite{swat_mega}, \cite{gpu_atlp}.
% XXX: How we compare to other, how to evaluate
% Benchmark => prove by evaluation intro statements

Our contributions are: \ul
%\item A classification of DP problems characteristics (matrix shape, dependency graph, ...)
\item A systematic approach to process data (top-down/bottom-up) and backtracking information (focus on running time and memory efficiency)
\item A language embedded in Scala (DSL) to express DP problems concisely (based on ADP)
\item Two implementations: Scala for CPU (features) and an CUDA for GPU (efficiency)
%\item Reuse of existing compiler technology (fusion) for a specific purpose
%\item State of the art parallel implementation of these classes on GPUs
%\item Normalization of the grammar into efficient productions
%\item Code generator to transform a grammar into efficient code for CPU, GPU (and FPGA)
\ule

\vfill
This project has been achieved in collaboration with Manohar Jonnalagedda. I also would like to thank the LAMP team, including Eugene Burmako, Andro Stucki, Vojin Jovanovic and Tiark Rompf who provided insightful advices and suggestions. I hope you will enjoy your reading. \vspace{.3cm}\\
\textit{Thierry Coppey}

\newpage
\setcounter{tocdepth}{2} \tableofcontents

\input{introduction}
\input{problems}
\input{design}
\input{implementation}
\section{Benchmarks}
{\color{red} XXX}

\section{Future work} \ul
\item Implementation for serial problems larger than memory, using hybrid (Myers and Miller's algorithm with $\log_k$ with $k$ depending on available memory)
\item Transforming non-serial into serial using aggregation functions/transformations
\item Avoid to maintain the cost matrix in memory by moving data in the wavefront
\item Non-serial scheduling for large problems (with memory loads for non-serializable)
\item Add FPGA target platform (George Nithin)
\item Pack the data => less memory transfer (i.e. GATC=>4 letters in 1 char)
\item Operate on larger words (ex 64 bits) to increase thread locality and reduce memory accesses
\ule

\begin{verbatim}
How to Encode multi-dimensional matrices efficiently
1. assume they have the same type put one after another => different dimensions ok
2. assume of same size => put into a struct
=> but using different pointers seems more reliable => completely different matrices => fixed list of matrices by dimensionality (O(1), O(n), O(n^2), ...) of structs (determined by number of indices to access object)

Core function F:
- in: s,t strings, neighbor costs: top, left, top+left, neighbor stats: top, left, top+left
- out: backtrack information, cost(i,j), stats
         stats (x)
          ||
          vv
stats -> [  ] -> new_stats (y')
(y)       || \
          vv  --+ backtrack info (Bxy)
      new_stats (x')

For stats, we need to maintain an horizontal and vertical front
For backtracking we need to maintain the whole table
... | . |
..A | B | min/max: Min(D)=Min(Min(C),Min(B))
----+---+ sum    : Sum(D)=Sum(C)+Sum(B)-Sum(A)
..C | D | avg    : sum both #cells and values then divide at appropriate cell
----+---+
we may not need to store what's the previous cell, however, the previous
cell information (usually limited range) is much more compact than the score(32-64 bits)
\end{verbatim}

\section{Conclusion}
{\color{red} XXX}

% ------------------------------------------------------------------------------------------------
\section*{Planning}
\textbf{Paper introduction}\ul
\item Problem to solve, what exists (related work), how we compare to other, how to evaluate
\item Contributions (3): 3 tensed sentences
\item benchmark => prove by evaluation intro statements
\ule

\subsubsection*{Roadmap}
\begin{tabular}{rl}
16.11 & Rules normalization and automatic backtracking \\
	& GenScala on LMS + GenCuda + LMS CudaCompiler \\
23.11 & Problem generalization: "cyclic keyword", Zucker problem / CudaLoop optimization \\
30.11 &--- Gap due to LMS missing knowledge \\
7.12 & Benchmarking, grammar analysis \\
14.12 & First thoughts for larger than device memory \\
21.12 & Writing report \\
28.12 & --- holiday --- \\
 4.01 & --- holiday --- \\
11.01 & Writing report: implementation description and plan for future work \\
18.01 & Writing report
\end{tabular}

\subsubsection*{Todo @TCK}\ul
\item Test/proof parsers are correct -- make sure implementation is correct
\item Automate test to compare against implementation
\item Benchmarks -- use CUDA profiler(?)
\item Write report
\item Port LibRNA for CUDA?
\ule

\subsubsection*{Todo @Manohar}\ul
\item Integrate LMS code generation into v4.
\item Fix Zuker coefficients
\ule

%Some GPU algorithms: http://hgpu.org/?cat=11
%Translation into C++: http://bibiserv.cebitec.uni-bielefeld.de/macports/resources/download/
%CUDPP libraries (but awfully big resulting binary): http://code.google.com/p/cudpp/
%13 dwarfs: http://developer.amd.com/afds/assets/presentations/2155_final.pdf
%http://tutorials.jenkov.com/java-reflection/fields.html
%http://lampwww.epfl.ch/~michelou/scala/scala-reflection.html
%
%Hint: use TypeClass to put a predicate on types
%  def fun[T: CanTranslateToC](...)
%  def fun[T](implicit ev:CanTranslateToC[T])
%  class CanTranslateToC[T] { def translate:String }
%  implicit def canTranslateInt = new CanTranslateToC[Int] = { def translate = "Int" }

% ------------------------------------------------------------------------------------------------
\newpage
%\usepackage{multicol}
%\usepackage{etoolbox}
%\patchcmd{\thebibliography}{\section*{\refname}}{\begin{multicols}{2}[\section*{\refname}]}{}{}
%\patchcmd{\endthebibliography}{\endlist}{\endlist\end{multicols}}{}{}
%\bibliographystyle{acm}
\bibliographystyle{plain}
\bibliography{bibliography.bib}
\end{document}
