\newpage
\section{Implementation} \label{implementation}
% ------------------------------------------------------------------------------------------------
\subsection{CUDA baseline} \label{baseline_impl}
In the project planning, an baseline implementation phase immediately followed the problem analysis (we also present the parallelogram matrix case). The goal of this phase is threefold:\ol
\item Better understand the challenges in CUDA implementation of dynamic programming problems and get on par with state-of-art implementations.
\item Have a baseline implementation that is independent of the hardware and that could be benchmarked. We also tried to contact the authors of \cite{swat_mega} and \cite{gpu_atlp} to obtain their implementation. The former provided us with their implementation, which turned out to address large serial problems whereas our focus was on smaller non-serial problems, the latter did not respond to our solicitations.
\item Have an optimal implementation that can serve as a   to be imitated and generalized by the code generation.
\ole

Leveraging the insights provided by \cite{gpu_atlp} and \cite{gpu_barrier}, we started with a basic implementation (where each CUDA thread processes one matrix line) with three additional optimizations:\ul
\item Memory accesses must be coalesced (memory accesses account for a significant part of the total running time, according to both manufacturer documentation and experiments \cite{perfeval_gpu})
\item Synchronization between threads can be done according to \cite{gpu_barrier}, additionally, we can slightly loosen the synchronization restrictions, as the paper describes a thread barrier whereas we only require a condition on previous thread progress (except for the parallelogram case, where we still require a barrier).
\item Computation progresses element-wise along the diagonal (maximizes the parallelism level)
\item Thread block size = warp size (32) to benefit from implicit synchronization within warps
\ule

% ----------------------------------------------
\subsubsection{Related work}
Since \cite{swat_mega} focuses on a different class of problem, we compare our implementation against \cite{gpu_atlp}, which provides an efficient matrix multiplication implementation. However, since we have neither the source code (or binary) nor the same evaluation hardware, we need to normalize the results. To do that, we present hardware differences and their result:

\def\unt#1{& \footnotesize #1}
\begin{table}[H]\begin{center}\begin{tabular}{lrrr} \toprule
\bf Graphic card &				& \bf Our 		& \bf  ATLP\cite{gpu_atlp} \\ \midrule
Model &						& GeForce GT 650M	& Tesla C1060 \\
Architecture, capability  &			& Kepler (3.0)	& GT200 (1.3) \\
Memory \unt{Mb}				& 1024		& 4096 \\
CUDA cores &					& 384		& 240 \\
Clock (core, memory) \unt{MHz}	& 756, 1953	& 1300, 1600 \\
Memory bus \unt{bit}				& 128		& 512 \\
Memory bandwidth \unt{GB/s}		& 28.8		& 102.4 \\
Processing power \unt{GFLOPS}	&564.5		& 622.08 \\ \midrule
\bf Processing speedup & 		& 1			& 1.07 \\
\bf Memory speedup & 			& 1			& 3.55 \\ \bottomrule
\end{tabular}\end{center}\caption{Graphic cards technical specifications (source: \href{http://en.wikipedia.org/wiki/Comparison_of_Nvidia_graphics_processing_units}{Wikipedia})}\end{table}

\begin{table}[H]\begin{center}\begin{tabular}{lrrrrrrrrrr} \toprule
\bf Matrix size & 128 & 256 & 512 & 1024 & 1536 & 2048 & 2560 & 3072 & 3584 & 4096 \\ \midrule
\bf No split & 0.07 & 0.09 & 0.19 & 0.59 & 1.27 & 2.25 & 3.51 & 5.07 & 6.92 & 9.06 \\
\bf Split at 1 & 0.06 & 0.07 & 0.08 & 0.14 & 0.26 & 0.47 & 0.77 & 1.21 & 1.80 & 2.57 \\ \bottomrule
\end{tabular}\end{center}\caption{ATLP\cite{gpu_atlp} results: matrix chain multiplication, execution time (in seconds)}\end{table}

% ----------------------------------------------
\subsubsection{Results}
We present here the timings of our baseline implementation. For correctness, we first implemented a CPU single thread version (in C) that we used to compare CUDA results against. Input data is made of random numbers. The implemented dynamic programming problems are:\ul
\item Rectangle: Smith-Waterman with arbitrary cost (\S\ref{swat_arbitrary})
\item Triangle: matrix chain multiplication (\S\ref{mat_mult_plain})
\item Parallelogram: polygon triangulation (\S\ref{polygon_tri}) using a matrix larger than necessary (\S\ref{problems_end}). Note that this implementation uses at most 32 blocks to prevent dead locks on our hardware (restriction due to the number of concurrent threads on the device).
\ule

\begin{table}[H]
\begin{center}\begin{tabular}{rlrrr} \toprule
\bf Matrix size & \bf Comment & \bf R & \bf T & \bf P \\ \midrule
1024 & CPU					& 1.965		& 1.191		& 6.069 \\
2048 & CPU					& 27.229		& 15.296		& 57.323 \\
4096 & CPU					& 			& 177.608	&  \\
1024 & GPU baseline			& 0.838		& 0.500		& 0.516 \\
1024 & GPU sync improved		& 0.642		& 0.316		& 0.343 \\
2048 & GPU P $\le32$ blocks		& 2.864		& 1.427		& 2.096 \\
4096 & GPU 8 splits				& 21.902		& 8.841		& 16.767 \\
8192 & GPU 64 splits			& 159.058	& 62.064		& 135.793 \\
12288 & GPU 256 splits			& 419.030	& 196.971	& 460.912 \\
\bottomrule \end{tabular}\end{center}
\caption{Execution time (in seconds) for R=rectangle, T=triangle, P=parallelogram}
\end{table}

% ----------------------------------------------
\subsubsection{Results discussion} \label{results_discussion} \ul
\item \textbf{User interface:} It has been put in evidence in \cite{perfeval_gpu} that using the GPU exclusively for CUDA or in combination with UI display (Mac OS) affects the performance (GeForce 330M). With the newer architecture, this difference has been reduced to less than 3.5\%, decoupled UI and CUDA   performing best. So we can safely ignore this issue.
\item \textbf{Blocks synchronization:}\ul
	\item Removing {\tt \_\_threadfence()} before the synchronization is not syntactically correct but results still remains valid, this confirms the observation made by \cite{gpu_barrier}. Speedup for matrix size of 1024 are 67ms (parallelogram) 100ms (triangle) 180ms (rectangle).
	\item In the parallelogram case, using all threads to monitor other blocks status instead of the first one only results in a 6.4x speedup (22.72$\to$3.52ms) for the parallelogram.
	\ule
\item \textbf{Multiple threads per matrix cell:} in the case of a triangular matrix, at each step, the number of cells to be computed (on the diagonal) decrease while the computation complexity increases (there is one more dependency). According to \cite{gpu_atlp}, the solution lies in adaptive thread mapping, using more than one thread to compute one matrix cell, depending on the complexity. However, in our setup (memory layout+algorithm+hardware), we did not find any improvement by doing so. We want to explore the reason for that: we pose as hypothesis that the bandwidth is the bottleneck of our setup and test it.\ul
\item

First we need to prove that we use almost all the available memory bandwidth: for matrix multiplication, in a triangular matrix, we have
\[\text{Total transfer}=\frac{n(n+1)}{2} \text{ writes} + \sum_{i=0}^{n-1} 2 i \cdot (n-i) \text{ reads}\]
where each write is 10 bytes (long+short), and each read is 8 bytes (long). For $n=4096$ we transfer
% n*(n + 1)/2*12 + Sum[2*i*(n - i), {i, 0, n - 1}]*8
183'352'614'912 bytes which corresponds to 183.35GB. In 8.841 seconds, we can transfer theoretically at most $8.841\cdot 28.8 = 254.6 \rm GB$. Hence  72\% of the algorithm running time is spent into memory accesses.

\item On a 4096 matrix, if we assume that the \cite{gpu_atlp} card would have the same bandwidth as our card, their running time would be
\[2.57 \cdot (1-.72) + 2.57 \cdot 0.72 \cdot \tfrac{102.4_{GB/s}}{28.8_{GB/s}} = 7.30\rm s_{\text{ ATLP}} < 8.84\rm s_{\text{ our}}\]
This shows that our algorithm is comparable to theirs. However, we must avoid a close comparison because the fundamental hardware differences would make a tight computation almost intractable (additionally, we do not have \cite{gpu_atlp} source code).
\ule
As a conclusion, (1) it seems that the technique used in \cite{gpu_atlp} brings more performance improvement with legacy hardware, however this remains a supposition (as we can not compare) and (2) we are slightly worse than one of the best current implementations.

\item \textbf{Number of threads:} reducing the number of threads launched at different splits of the algorithm (especially in latest splits in rectangular and triangular shapes) does not bring any speedup. Even worse, it slows down slightly the computation. We might attribute this to a better constant transformation by the compiler. Hence, having many idle threads does not impede performance.

\item \textbf{Unrolling:} unrolling the inner loops (non-serial dependencies) a small number of times provide some speedup, for a 2048-matrix respectively 10.9\% (rectangle, $2.765s\to 2.464s$), 14.1\% (triangle, $1.427s\to 1.225s$) and 9.7\% (parallelogram $1.539s\to 1.389s$). The best experimental number of unrolling is 5.
\ule

% ------------------------------------------------------------------------------------------------
\subsection{Scala parsers} \label{scala_parsers}
The Scala parsers consist in 4 traits that are used to construct a DSL program:\ul
\item \textbf{Signature:} abstraction to define input ({\tt Alphabet}) and output ({\tt Answer}) types, and the aggregation function. The signature is implemented by all other traits (in particular algebras and grammars).
\item \textbf{BaseParsers:} serves as basis for the two other traits and defines common features. It implements the {\tt Parser} abstraction and all its inheriting classes: {\tt Tabulate}, (abstract) {\tt Terminal}, {\tt Aggregate}, {\tt Filter}, {\tt Map}, {\tt Or}, {\tt Concat}. Terminals are further specialized in the two other traits (ADPParsers and TTParsers). The parser abstraction specifies 3 methods:\ul
	\item {\tt apply(subword)} computes the parser result; it is used to obtain the corresponding results.
	\item {\tt unapply(subword,backtrack)} computes the previous step of the backtrack by returning subsequences at the origin of the result; it is invoked recursively to obtain the full backtrack trace.
	\item {\tt reapply(subword,backtrack)} is very similar to apply, except that it  computes only the results matching the backtrack. It is used to construct the result corresponding to a backtrack trace (possibly in a different domain, pretty printing, ...).
	\ule
	To support analysis, the parsers carry additional values:\ul
	\item Minimum and maximum yield size: functions evaluated recursively except for tabulations where value is attributed in the yield analysis phase.
	\item Number of inner alternatives: helps counting alternatives, thereby guaranteeing an unique number for each (provided that parsers obtain non-overlapping ranges).
	\item Number of inner moving concatenations: helps determining required storage for the backtrack as well as retrieving the appropriate index in the backtrack phase
	\ule
	Additionally, the BaseParser implements the analysis that is shared by both the Scala and the CUDA version: dead rules elimination, yield analysis and dependencies ordering. Finally, it provides some implicit functions to flatten nested tuples (that are constructed by multiple concatenations).
\item \textbf{ADPParsers:} used as basis for a single track DP grammar (using one input sequence). It defines the concatenation operator $\sim$ ({\tt Concat} wrapper), and the terminals (empty, element and sequence). Additionally, it defines the interface functions {\tt parse(input)}, {\tt backtrack(input)} and {\tt build(in,backtrack)} that respectively compute the result, the backtrack and the result corresponding to a trace.
\item \textbf{TTParsers:} used to define two-track DP grammar (using a pair of sequences as input). Similarly, this class defines concatenations $-\!\!\sim$ and $\sim\!\!-$, terminals (for each track) and the {\tt parse(in1,in2)}, {\tt backtrack(in1,in2)} and {\tt build(in1,in2,backtrack)} functions.
\ule

\begin{figure}[H]\begin{center}\setlength{\unitlength}{.6cm}\begin{picture}(14,11)
\put(3,8){\tbox{8}{2.5}{{\bf Signature} \footnotesize\\ Types: Alphabet, Answer \\ $h$ (aggregation function)}}
\put(0,4){\tbox{14}{2.5}{{\bf BaseParsers} \footnotesize\\ Tabulate, Terminal, Aggregate, Filter, Map, Or, Concat \\ Analysis: dead rules, yield analysis, dependencies}}
\put(0,0){\tbox{6}{2.5}{{\bf ADPParsers} \footnotesize\\ $\sim$, $\sim(a,b,c,d)\sim$ \\ Single track terminals}}
\put(8,0){\tbox{6}{2.5}{{\bf TTParsers} \footnotesize\\ $-\!\!\sim$, $\sim\!\!-$ \\ Two-tracks terminals}}
{\linethickness{1.5pt}\put(3,2.5){\vector(1,1){1.5}}\put(11,2.5){\vector(-1,1){1.5}}\put(7,6.5){\vector(0,1){1.5}}}
\end{picture}\end{center}\caption{Scala parsers class diagram (simplified)}\end{figure}

% ------------------------------------------------------------------------------------------------
\newpage
\subsection{Code generation} \label{codegen}
The code generation step produces multiple outputs that are tightly bound to each other. Besides the Scala wrapper (a simple JNI interface), in the C/CUDA code generated we distinguish:\ol
\item JNI input and output conversion functions
\item Host helpers for memory management and scheduling of CUDA kernels
\item CUDA matrix computation, which can be further decomposed into matrix scheduling (loops) and (matrix cell) computation.
\item CUDA backtrack collection kernel
\ole

\begin{figure}[H]\begin{center}\setlength{\unitlength}{.6cm}\begin{picture}(16,8)
\put(0,-.5){
{\color{lightgray}\put(0,7){\tbox{4}{1}{\footnotesize\bf BaseParsers}}
	\put(0,2){\rotatebox{90}{\tbox{4}{1}{\footnotesize\bf ADPParsers}}}
	\put(1.5,2){\rotatebox{90}{\tbox{4}{1}{\footnotesize\bf TTParsers}}}
	{\linethickness{1.5pt}\put(.5,6){\vector(1,1){1}}\put(2,6){\vector(0,1){1}}}}
{\linethickness{1.5pt}\put(6,6){\vector(-7,2){3.5}}\put(8,1.33){\vector(3,1){2}}\put(8,1.33){\vector(3,-1){2}}}
\put(3,0){\tbox{6}{6}{{\bf CodeGen} \footnotesize\\ code generation: parsers, backtrack, helpers, JNI \\[12pt] CodeCompiler}}
\put(10,3.5){\tbox{6}{2.5}{{\bf CodeHeader} \footnotesize\\ Types conversion, headers management}}
\put(10,1.5){\tbox{6}{1}{\bf ScalaCompiler}}\put(10,0){\tbox{6}{1}{\bf CCompiler}}
\moveto(2,2)\lineto(2,1.5)\lineto(2.5,1.5)\strokepath\put(2.5,1){\vector(1,0){.5}}
\moveto(.5,2)\lineto(.5,1)\lineto(2.5,1)\strokepath\put(2.5,1.5){\vector(1,0){.5}}
\put(-1.25,-.1){\tbox[0l]{4.5}{1}{\footnotesize automatic call \tiny\\ if CodeGen mixed-in}}
}
\end{picture}\end{center}\caption{Code generation and runtime engine class diagram (simplified)}\end{figure}

% ----------------------------------------------
\subsubsection{Scala structures conversion (JNI)}
Since general Scala types can be extremely complex and might depend of the JVM context (file stream, closures, ...), we want to restrict the supported types; additionally types should be of fixed size for more efficient processing and easier memory allocation. We support the following types:\ul
\item \textbf{Primitive types:} natively supported in both Java and C. Since there is some little semantics difference between these two languages types, we used C (signed) types as reference. Supported types are: boolean, byte (unsigned char), char, short, int (32bit), long (64bit), float and double.
\item \textbf{Empty case classes:} user-defined types might be more complex, so we allow users to define case classes that serve as data container and would be translated into C {\tt struct}s.
\item \textbf{Tuples:} if the user-defined type is fairly simple, a named case class might be cumbersome. Tuples are a syntactical lightweight alternative to case classes, although they translate very similarly. Since Tuple classes are generic and can carry different member types; need to name tuple types uniquely, according to their arity and inner types.
\ule

Currently we use {\tt Manifest}s and reflection to extract types, and convert their string representation into our restricted subset. Manifests expands tuple inner types and reflection can be used to find class member's types. This imposes the additional restriction that we can not nest tuples into case classes, because generic types are then erased. However, the same effect could be achieved with Scala 2.10 {\tt TypeTag}s, converting immediately to concrete type tree representation using macros expansion\footnote{Hint provided by Eugene Burmako, \url{https://gist.github.com/4407488}}.

The JNI functions are involved at input to decode sequences arrays and at output, to encode the result and possibly its corresponding trace. Input method is constructed in two steps:\ul
\item Recursively obtain the classes and accessor methods of the composite input type. A subtle variation is that case classes primitive types are immediately converted into native types whereas tuple members are boxed in their respective class (i.e. {\tt java.lang.Integer}, ...).
\item For each element of the input array, retrieve the objects recursively and write their primitive values in the corresponding {\tt struct} array.
\ule
The output method consist of two different steps:\ul
\item Converting the result into its JVM counterpart by using the opposite rule as for decoding input (but with JNI types specified in the constructor lookup instead of accessors).
\item Optionally encoding the backtrack: this is pretty straightforward as the structure is more regular (and make uses of Lists); additional care should be taken to avoid bloating concatenation indices lists with unnecessary elements (as C uses fixed memory whereas Scala lists length might vary).
\ule

% ----------------------------------------------
\subsubsection{Host wrappers}
Host wrappers are functions bridging between JNI and CUDA; their duties are:\ul
\item Exposing JNI parsing and backtracking functions
\item Calling appropriate conversion methods
\item Allocating host and CUDA memory (and managing transfers between them)
\item Launching CUDA kernels: matrix computation, backtrack, and possibly aggregation within window (additional aggregation among window results, would this option be set)
\ule

One peculiarity of our execution environment, is that the kernel execution duration is bound to approximately 10 seconds\footnote{Hard limit imposed by the operating system. Although workarounds exist for Linux and Windows (requiring a second graphic card to display the UI), none of them is compatible with Mac OS. Eventually, a hack has been devised to force the UI on CPU while keeping the dedicated CUDA card powered; unfortunately this does not alleviate the kernel execution timeout.}. To solve this issue, we estimate the overall complexity of matrix computation, which allows us to estimate running time, then break computation into multiple kernels sufficiently small to fit in the time limit.

Since computations are made diagonal-by-diagonal (see \ref{matrix_scheduling}), we can easily decompose the matrix computation by adapting the number of diagonals computed per kernel. The global complexity being the product of the number of elements and the complexity per element, the latter being equal to the number of unbounded concatenations (where maximal size is infinite).

\textbf{Problems larger than device memory}\\
Problems larger than the device memory can actually be processed on recent CUDA devices (with CUDA architecture $\ge 2.0$) as these are able to address the main memory from the device. However, since the distance between CUDA processors and memory is increased, there is an approximate $5\times$ slowdown penalty to be paid in this configuration (experimentally, on a $1024\times 1024$ triangular matrix). Nevertheless, this workaround implementation has 2 benefits:\ul
\item It allows larger problem to be solved, with very little implementation effort, would the user be patient enough for the computation to terminate
\item It provides a good estimation of the main memory usage penalty, and thereby a strong argument in favor of the implementation described in \ref{ns_mem_transfer} (with lest than 1\% overhead due to transfers). However, since we have not found concrete applications with such matrix size, the benefit of supporting large matrices is unclear, hence we leave the optimal implementation for future work.
\ule

% ----------------------------------------------
\subsubsection{Matrix computation scheduling} \label{matrix_scheduling}
Similarly as in the baseline implementation, progress is made along the diagonal (see \ref{mem_layout}) and each thread is responsible of one line. That is, the matrix is swept horizontally by a <<diagonal of threads>>, that are enabled only if they are within a valid matrix cell.

\begin{figure}[H]\begin{center}\setlength{\unitlength}{.6cm}\begin{picture}(6,6)
	\def\Cfl2#1{#1{0,4}#1{0,3}#1{1,3}#1{0,2}#1{1,2}#1{2,2}#1{0,1}#1{1,1}#1{2,1}#1{3,1}#1{0,0}#1{1,0}#1{2,0}#1{3,0}#1{4,0}}
	\Cfl2{\Cg}
	{\color{cyan}\Cd[0,1]{4,1}{2.8}\Cd[0,1]{4,2}{1.8}\Cd[1,0]{1,4}{2.8}\Cd[1,0]{2,4}{1.8}\Cd[1,1]{3,3}{0.8}\Cd[2,1]{2,3}{1.8}\Cd[1,2]{3,2}{.9}}
	\Cd[0,1]{4,3}{0.8}\Cd[1,0]{3,4}{0.8}
	\multiput(3.5,5.5)(1,-1){6}{\circle{.4}}
	\multiput(0,0)(1,0){7}{\line(0,1){6}}\multiput(0,0)(0,1){7}{\line(1,0){6}} % matrix
	\put(3.5,5.5){\color{lightgray}\line(1,-1){5}}
	\multiput(3.7,5.5)(1,-1){6}{\color{red}\linethickness{1.5pt}\vector(1,0){2}}
	\put(8.6,0.05){\tiny thread 0}
	\put(3.6,5.75){\tiny thread 5}
\end{picture}\end{center}\caption{<<Diagonal of threads>> and maximal dependencies}\label{fig:diag_deps}\end{figure}

Special care must be taken to handle computation dependencies: within a warp, all threads are executed at the same time, hence no synchronization is necessary. To benefit from this implicit synchronization, we set block size being equal to wrap size. It remains to provide inter-block synchronization: dependencies are along line, column and possibly intermediate elements. By induction on rows and columns, it suffice to have the last column and row element valid. Since line is computed by the current thread (thereby valid), it only remains to guarantee that the column element of the previous line is valid (in figure \ref{fig:diag_deps}, previous refers to the line immediately below). To do that, each block writes last valid diagonal in a <<lock>> array, and next block need only to wait (polling) until desired element is marked valid. Notice that {\tt \_\_threadfence} is not mandatory (thereby slightly improving performance), verifying the observation of \cite{gpu_barrier}.

\begin{lstlisting}[language=C,caption=Synchronization with previous thread block (active waiting)]
__global__ void gpu_solve(/*...*/ volatile unsigned* lock, // = {0}
		unsigned d_start, unsigned d_stop) {
	const unsigned tB = blockIdx.x;
	unsigned tP=d_start; // block progress

	for (unsigned diag=d_start; diag<d_stop; ++diag) {
		/* ... compute diagonal values ... */

		// __threadfence();
		if (threadIdx.x == 0) {
			lock[tB] = ++tP;
			if (tB > 0) while(lock[tB-1]<tP) {}
		}
		__syncthreads();
	}
}
\end{lstlisting}

% ----------------------------------------------
\subsubsection{Parsers code generation}
Parsers generation is independent of user-defined function generation (see \ref{user_fun_gen}). Tabulation inner parsers are first wrapped in additional aggregation (by $h$, thereby ensuring they produce at most one result) and normalized (according to \ref{normalization}); code generation then occurs recursively, producing a list of loops and conditions, and body (possibly with a hoisted part). Additionally, position variables are maintained and subrule index and concatenation indices are propagated. We give an overview of each parser transformation:\ul
\item \textbf{Terminal:} provides its own C code, which correspond usually to the input element value, its position or the position of the matching range.
\item \textbf{Tabulate:} is a simple value load, possibly wrapped into a validity check. Useless validity verification can be removed by marking the tabulation as <<always valid>>.
\item \textbf{Aggregate:} corresponds to an intermediate (value,backtrack) pair where inner parsers write their result; outermost aggregation is written back to corresponding (cost, backtrack) matrices. Validity information, and concatenation indices are propagated within backtrack. To preserve a correct semantic, inner aggregations body is hoisted outside loops and condition checks of the enclosing parser.
\item \textbf{Or:} since parsers are normalized and operate on a single aggregation result, it suffice to emit sequentially code of alternatives.
\item \textbf{Map:} wraps its argument into a the user-defined function call
\item \textbf{Filter:} wraps its body into user-defined condition check
\item \textbf{Concat:} fixed size concatenation are wrapped in simple conditions; moving concatenations are wrapped in a {\tt for} loop. The loops and conditions are further simplified to reduce range and remove useless conditions before actual code is emitted.
\ule

Intermediate types must be correctly declared. To do that each user-defined function provides its input and output types. Aggregation temporary values declaration is ensured by a \textit{exists-or-declare} header policy that is called for every type declaration.

% ----------------------------------------------
\subsubsection{Backtracking on the GPU}
The backtracking is processed similarly to the Scala parser, the major difference being that since we are generating C code, we can provide an immediate mapping from the subrule index to the backtrack elements to add to the trace. The backtrack is done in 3 steps:\ul
\item If a window is set, the windowing aggregation kernel is run to determine the position of the best result within the matrix. Otherwise the best position can be found at the last computed element of the matrix.
\item For a $m\times n$ matrix, allocate a $m+n$ vector with two heads (reading, writing, initialized at the same position). Write the best element in the vector.
\item While there is a vector element that has been written but not read\ul
	\item From the parser id and its position retrieve the corresponding (subrule, concatenation indices) pair by reading in the corresponding matrix cell
	\item Using this, write new backtrack items that are at the origin of the current element.
	\ule
\ule

Since code is generated, it is possible to write the last step using a switch case, thereby flattening the writes in the vector (compared to recursive calls in Scala). Finally, since the trace has to be reversed, we can obtain this transformation for free by constructing the trace list from the end in the JNI conversion. Reversing the list presents the advantage that the trace is immediately usable to construct the desired element. It might be possible that Scala and CUDA parsers provide different traces to construct the same result, because the trace verifies the dependency order, which is only a partial order.

% ----------------------------------------------
\subsubsection{User functions generation} \label{user_fun_gen}
The user generation function needs to be tightly integrated with the rest of the code generation. To do that, we need to establish a relation between the Scala function and its C counterpart. This is done by modifying the Scala function such that it embeds its C code and related types (input, output and possibly internal structures). To do that, LMS is used to generate both Scala and C code (as the user would want to write only once his function, using the corresponding LMS {\tt Rep} types). The two implementations are then mixed to provide the augmented Scala function that can then be used at appropriate places by either the Scala parsers or the code generator.

Actually, the idea of mixing the two implementations into a single function emerged from experiments with the Scala macros \cite{scala_macros}, where it is possible to modify the AST of the Scala program before actually compiling it. Macros could also be an alternative to LMS in the sense that they have the same power in this particular case (because the code is just converted from Scala to C and does not benefit of additional run-time information); however, relying only on macros would imply rewriting significant portions of code conversion, which might end up being a duplicated effort with LMS. The most interesting use of the macros would actually be to stage plain Scala to its LMS representation in the <<context>> of user functions, thereby unleashing the power of LMS without forcing the DSL user to explicitly specify {\tt Rep} types\footnote{Since this is an ongoing project at LAMP with different schedule as this project, we do not want to duplicate effort currently but might integrate it at a later stage.}.

Another advantage of using LMS only for user-specific function, is that it does not impose any restriction on the types manipulated by Scala, thereby providing the opportunity to solve the DP problem (possibly on CUDA using restricted types) and apply the solution (in Scala) on complex types that would have no representation in LMS.

% ------------------------------------------------------------------------------------------------
\subsection{Runtime execution engine}
The runtime execution engine is made of two instrumented compilers:\ul
\item A wrapper for {\tt g++} and {\tt nvcc} that can combine different file types ({\tt .h}, {\tt .c}, {\tt .cu}) into a JNI library which is then loaded into the current JVM instance. If necessary, paths can be customized to fit the user environment.
\item A wrapper for the Scala compiler, which allow the creation of Scala interface to the freshly compiled JNI libraries. It should be noted there that using {\tt VirtualDirectory} as compilation target prevents the interaction with JNI, hence physical path has to be used.
\ule

These two compilers interfaces are then mixed in another class that transform the previously (see \ref{codegen}) generated code, fixing input sizes and splits (number of kernels to launch to respect the time limit) constants, and execute it.

% ------------------------------------------------------------------------------------------------
\newpage
\subsection{LibRNA}
Since the energy computation for RNA secondary structure prediction (folding the sequence in two dimensions) involve complex coefficients and computations (seemingly standardized in coefficient files), we might want to provide the user with a simple interface to benefit from it. To do that, we based our library on the work of GAPC\cite{gapc_thesis} which itself is based on \href{http://www.tbi.univie.ac.at/~ivo/RNA/}{ViennaRNA}\cite{vienna_rna}. Since the library is provided in C, we rely on JNI to reuse the code without modifying it; this allows Scala to immediately benefit from it, but also makes possible to write a GPU version, provided that the related functions are simple enough to be expressible in CUDA. Our work in this direction is mainly focused on integration, we do not want to discuss the implementation details here but simply give a overview of what we transformed and adapted to suit our needs.

In the first phase, we adapted the library embedded in GAPC to obtain coefficients. Since GAPC is written in C, we had to write a JNI interface to let the Scala code communicate with the libraries. Once this step has been achieved, we focused on obtaining correct results for RNA folding. This has been achieved by a thorough analysis of the GAPC related code, and took quite a long time due to bugs that were hard to find.

In parallel with this work, we focused on making the code compatible with CUDA. We managed to significantly reduce its size by removing unused functions (actually, all the programs of the Vienna package reuse the library, each introducing its own functions). This also enabled us to have a better understanding of the involved computations, thereby helping us to clearly separate the coefficient file processing and the energies computations. We also provided small optimizations towards parallelization and simplified the sequence management (because it needs to be converted in a particular format for the library to efficiently process it).

Once the library was ready to fit on CUDA devices, we integrated it into DynaProg. Unfortunately, since the library adds a significant volume of code (because some coefficients are embedded in C files), the compilation process length was increased (from approx. 2 to 7 seconds). To reduce this penalty (towards benchmarking), we introduced memoization of the compilation results in our code generator, thereby avoiding duplicated compilations of the program for same length of sequences (generated programs are tailored for particular sequences lengths).

% ------------------------------------------------------------------------------------------------
\newpage
\section{Usage} \label{usage}
\subsection{Program examples}
In this section, we explain how to use the DynaProg DSL using an example based approach. We focus on three additional examples: Smith-Waterman (\S\ref{swat_affine}) and Needleman-Wunsch to present two-tracks grammars and multiple algebras, RNAfold\cite{gpu_rnafold} (\S\ref{zuker}, alternative) to describe RNA library usage and reconstruction from backtrack trace, and finally we extend matrix chain multiplication (\S\ref{adp_practice}) with CUDA code generation.

% ----------------------------------------------
\subsubsection{Smith-Waterman and Needleman-Wunsch} \label{ex_swat}
First define a signature that can fit both algebrae, then specify for each algebra the related functions. In this example, both algebra operate on the same output domain and share the same optimization function (although this is not true in general).
\begin{lstlisting}[language=Scala,captionpos=none]
trait SeqAlignSignature extends Signature {
  type Alphabet = Char
  def start(x:Unit):Answer
  def gap1(g:(Int,Int),a:Answer):Answer
  def gap2(a:Answer,g:(Int,Int)):Answer
  def pair(c1:Alphabet,a:Answer,c2:Alphabet):Answer
}

trait SmithWatermanAlgebra extends SeqAlignSignature {
  type Answer = Int
  override val h = max[Int] _
  private val open = -3
  private val extend = -1
  def start(x:Unit) = 0
  def gap1(g:(Int,Int),a:Int) = gap2(a,g) // by symmetry
  def gap2(a:Int,g:(Int,Int)) =
    { val size=g._2-g._1; Math.max(0, a + ( open + (size-1)*extend )) }
  def pair(c1:Char,a:Int,c2:Char) = a + (if (c1==c2) 10 else -3)
}

trait NeedlemanWunschAlgebra extends SeqAlignSignature {
  type Answer = Int
  override val h = max[Int] _
  private val open = -15
  private val extend = -1
  def start(x:Unit) = 0
  def gap1(g:(Int,Int),a:Int) = gap2(a,g) // by symmetry
  def gap2(a:Int,g:(Int,Int)) =
    { val size=g._2-g._1; a + ( open + (size-1)*extend ) }
  def pair(c1:Char,a:Int,c2:Char) = a + (if (c1==c2) 4 else -3)
}
\end{lstlisting}

To obtain a visual representation of the alignment, a naive idea would be to construct the two aligned strings immediately in the forward phase (in the {\tt Answer}). However, this approach must be avoided as it is extremely inefficient, both in terms of running time and space complexity because intermediate strings are created (and stored in memory) for every intermediate result. The correct way to solve this issue is to use backtracking and forward construct these strings with a pretty printing algebra:
\begin{lstlisting}[language=Scala,captionpos=none]
trait SeqPrettyPrint extends SeqAlignSignature {
  type Answer = (String,String)
  def in1(k:Int):Alphabet; def in2(k:Int):Alphabet // make it visible
  private def gap(sw:(Int,Int),in:Function1[Int,Char]) = {
    val g=(sw._1 until sw._2).toList
    (g.map{x=>in(x)}.mkString,g.map{x=>"-"}.mkString)
  }
  def start(x:Unit) = (".",".")
  def gap1(g:(Int,Int),a:Answer) =
    { val (g1,g2)=gap(g,in1); (a._1+g1,a._2+g2) }
  def gap2(a:Answer,g:(Int,Int)) =
    { val (g2,g1)=gap(g,in2); (a._1+g1,a._2+g2) }
  def pair(c1:Char,a:Answer,c2:Char) = (a._1+c1,a._2+c2)
}
\end{lstlisting}

Finally, we describe the associated grammar and the programs that mixes the algebrae and the grammar. Note that we need one instance of each pair of grammar and algebra. Once we have done that, we can request scores and backtracks associated with an evaluation algebra (Smith-Waterman or Needleman-Wunsch) and reuse the obtained backtrack to construct the matching aligned sequences:
\begin{lstlisting}[language=Scala,captionpos=none]
trait SeqAlignGrammar extends TTParsers with SeqAlignSignature {
  val axiom:Tabulate = tabulate("M",(
    empty                     ^^ start
  | seq1() -~ axiom           ^^ gap1
  |           axiom ~- seq2() ^^ gap2
  | el1    -~ axiom ~- el2    ^^ pair
  ) aggregate h)
}

object SeqAlign extends App {
  object SWat extends SeqAlignGrammar with SmithWatermanAlgebra
  object NWun extends SeqAlignGrammar with NeedlemanWunschAlgebra
  object pretty extends SeqAlignGrammar with SeqPrettyPrint
  val seq1 = "CGATTACA"
  val seq2 = "CCCATTAGAG"

  def align(name:String,s1:String,s2:String,g:SeqAlignGrammar) = {
    val (score,bt) = g.backtrack(s1.toArray,s2.toArray).head
    val (a1,a2) = pretty.build(s1.toArray,s2.toArray,bt)
    println(name+" alignment\n- Score: "+score)
    println("- Seq1: "+a1+"\n- Seq2: "+a2+"\n")
  }
  align("Smith-Waterman",seq1,seq2,SWat)
  align("Needleman-Wunsch",seq1,seq2,SWat)
}
\end{lstlisting}

% ----------------------------------------------
\newpage
\subsubsection{RNA folding} \label{ex_rnafold}
We define a signature with two evaluation algebras: {\tt RNAFoldAlgebra} actually computes the folding whereas {\tt RNAFoldPrettyPrint} describes the folding in a string. The energy functions are provided by an external library ({\tt LibRNA}). This library encodes substring as (first character, last character) whereas our framework encodes them as (first character, first character + length), which explains the off-by-one corrections. {\tt energies} variable is set to false in {\tt RNAFoldPrettyPrint} because this algebra does not involve the LibRNA energies functions (that require encoding the input RNA sequence in a special format; this option is enabled by default in the RNASignature trait).

\begin{lstlisting}[language=Scala,captionpos=none]
trait RNAFoldSig extends RNASignature {
  def hairpin(ij:(Int,Int)):Answer
  def stack(i:Int,s:Answer,j:Int):Answer
  def iloop(ik:(Int,Int),s:Answer,lj:(Int,Int)):Answer
  def mloop(i:Int,s:Answer,j:Int):Answer
  def left(l:Answer,r:Int):Answer
  def right(l:Int,r:Answer):Answer
  def join(l:Answer,r:Answer):Answer
}

trait RNAFoldAlgebra extends RNAFoldSig {
  type Answer = Int
  import librna.LibRNA._ // indexing convention: first base,last base
  def hairpin(ij:(Int,Int)) = hl_energy(ij._1,ij._2-1) // Eh
  def stack(i:Int,s:Int,j:Int) = sr_energy(i,j) + s // Es
  def iloop(ik:(Int,Int),s:Int,lj:(Int,Int)) =
      il_energy(ik._1,ik._2,lj._1-1,lj._2-1) + s // Ei
  def mloop(i:Int,s:Int,j:Int) = s
  def left(l:Int,r:Int) = l
  def right(l:Int,r:Int) = r
  def join(l:Int,r:Int) = l+r
  override val h = min[Answer] _
}

trait RNAFoldPrettyPrint extends RNAFoldSig {
  type Answer = String
  override val energies=false
  private def dots(n:Int,c:Char='.') = (0 until n).map{_=>c}.mkString
  def hairpin(ij:(Int,Int)) = "("+dots(ij._2-ij._1-2)+")"
  def stack(i:Int,s:String,j:Int) = "("+s+")"
  def iloop(ik:(Int,Int),s:String,lj:(Int,Int)) =
      "("+dots(ik._2-1-ik._1)+s+dots(lj._2-1-lj._1)+")"
  def mloop(i:Int,s:String,j:Int) = "("+s+")"
  def left(l:String,r:Int) = l+"."
  def right(l:Int,r:String) = "."+r
  def join(l:String,r:String) = l+r
}
\end{lstlisting}

\newpage
We can then define the associated grammar
\begin{lstlisting}[language=Scala,captionpos=none]
trait RNAFoldGrammar extends ADPParsers with RNAFoldSig {
  lazy val Qp:Tabulate = tabulate("Qp",(
    seq(3,maxN)        ^^ hairpin
  | eli   ~ Qp ~ eli   ^^ stack
  | seq() ~ Qp ~ seq() ^^ iloop
  | eli   ~ QM ~ eli   ^^ mloop
  ) filter basepairing aggregate h)

  lazy val QM:Tabulate = tabulate("QM",(Q ~ Q ^^ join) filter((i:Int,j:Int)=>i<=j+4) aggregate h)

  lazy val Q:Tabulate = tabulate("Q",(
    QM
  | Q ~ eli ^^ left
  | eli ~ Q ^^ right
  | Qp
  ) filter((i:Int,j:Int)=>i<=j+2) aggregate h)

  override val axiom = Q
}
\end{lstlisting}

In the application, we create two objects, each combining the grammar with a particular algebra. We can optionally specify a coefficient parameter file with {\tt setParams(file:String)}, otherwise the \textit{Turner2004} coefficients are used. The library is automatically loaded and fed with the sequence to produce correct energy coefficients. We request both the score and the backtrack trace (in {\tt bt}) so that we can reconstruct the folding using the pretty printing grammar.
\begin{lstlisting}[language=Scala,captionpos=none]
object RNAFold extends App {
  object fold extends RNAFoldGrammar with RNAFoldAlgebra
  object pretty extends RNAFoldGrammar with RNAFoldPrettyPrint

  val seq="aaaaaagggaaaagaacaaaggagacucuucuccuuuuucaaaggaagagg"

  val (score,bt) = fold.backtrack(seq.toArray).head
  val res = pretty.build(seq.toArray,bt)
  println("Folding : "+res+" (%5.2f)".format(score/100.0));
}
\end{lstlisting}

% ----------------------------------------------
\newpage
\subsubsection{Matrix multiplication with CUDA code generation} \label{ex_matmult_cuda_lms}
Leveraging the existing definitions of the signature and grammar (repeated here for convenience)
\begin{lstlisting}[language=Scala,captionpos=none]
trait MatrixSig extends Signature {
  type Alphabet = (Int,Int) // Matrix(rows, columns)
  val single:Alphabet=>Answer
  val mult:(Answer,Answer)=>Answer
}

trait MatrixGrammar extends ADPParsers with MatrixSig {
  val axiom:Tabulate = tabulate("M",
    (el ^^ single | axiom ~ axiom ^^ mult) aggregate h)
}
\end{lstlisting}
We need describe the algebra functions in the LMS syntax ({\tt RepWorld}) that we can later compile to use as regular functions, augmented with C code description (necessary for code generation). Finally, we need to mix the {\tt CodeGen} trait to enable code generation and provide the manifest for input and ouput types ({\tt Alphabet} and {\tt Answer}).

\begin{lstlisting}[language=Scala]
trait RepWorld extends NumericOps with TupleOps {
  type Alphabet = (Int, Int)
  type Answer = (Int, Int, Int)

  def hf(a: Rep[Answer]) :Rep[Int] = a._2
  def repSingle(a: Rep[Alphabet]): Rep[Answer] = (a._1, unit(0), a._2)
  def repMult(l: Rep[Answer], r: Rep[Answer]): Rep[Answer] =
    (l._1, l._2 + r._2 + l._1 * l._3 * r._3, r._3)
}

object MatrixMultLMS extends MatrixSig with MatrixGrammar
    with CodeGen with App {
  val tps=(manifest[Alphabet],manifest[Answer])
  override val benchmark = true // display timing measurements

  // Algebra is defined immediately in the concrete program
  type Answer = (Int, Int, Int)
  val concreteProg = new RepWorld with RepPackage
  override val h = minBy(concreteProg.gen(concreteProg.hf))
  val single = concreteProg.gen(concreteProg.repSingle)
  val mult = concreteProg.gen2(concreteProg.repMult)

  val input = List((1,2),(2,20),(20,2),(2,4),(4,2),(2,1),(1,7),(7,3)).toArray
  println(parse(input).head) // -> 1x3 matrix, 122 multiplications
}
\end{lstlisting}

The complete source file of the presented problems can be found in the {\tt report/} folder. For further examples and variants, we encourage you to have a look in the {\tt examples/} folder.

% ------------------------------------------------------------------------------------------------
\newpage
\subsection{Other usage options}
We here provide a list of relevant variables and traits that the programmer might be interested to use. This list only serves the purpose of documenting features that might otherwise be difficult to find within the code.

Although the whole program can be defined in a single trait, it is preferable to cleanly separate the signature from the grammar and the algebra, this good practice would help adding new algebrae easily. The signature needs to inherit either from {\tt Signature} or {\tt RNASignature}, would the RNA folding energies be needed. The grammar can be either single track or two-tracks by inheriting respectively from  {\tt ADPParsers} and {\tt TTParsers}. Note that RNA folding only works for single track grammars and library setup is enabled by the usage of the trait {\tt RNASignature} (this could be changed by disabling the flag {\tt energies}).

The code generator is used by simply mixing in the {\tt CodeGen} trait, using the following idiom
	\[\text{\tt val tps=(manifest[Alphabet],manifest[Answer])}\]
anywhere at the intersection of the CodeGen inheritance and definition of these types (usually in the final program). Further configuration of the execution environment can be tuned by overriding the following variables: {\tt compiler} (for system paths and flags), {\tt cudaSplit} and {\tt cudaDevice}. The {\tt benchmark} flag can be set to enable timing measurements. Also it is possible to use bottom-up parsers with Scala to reduce the stack size by enabling the {\tt bottomUp} flag. If special concatenations are needed, it is possible to replace the $\sim$ concatenation by $\sim\.(l_{\rm min},l_{\rm max},r_{\rm min},r_{\rm max})\.\sim$ where $l,r$ design respectively the yield size of left and right operands.

Finally, the user can look in the files {\tt ADPParsers.scala} and {\tt TTParsers.scala} for a list of the available terminals, and possibly create new ones.
